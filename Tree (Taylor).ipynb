{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b9ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"TaylorTree\").getOrCreate()\n",
    "\n",
    "data = spark.read.csv(\"taylor.csv\", header=True, inferSchema=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f3935ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, minute, second, col, to_date, day, month, to_timestamp\n",
    "\n",
    "data = data.withColumn(\"duration\", to_timestamp(col(\"duration\"), \"dd/MM/yyyy HH:mm:ss\"))\n",
    "data = data.withColumn(\"minutes\", hour(col(\"duration\")))\n",
    "data = data.withColumn(\"seconds\", minute(col(\"duration\")))\n",
    "data = data.withColumn(\"duration\", col(\"minutes\") * 60 + col(\"seconds\"))\n",
    "data = data.drop(\"minutes\")\n",
    "data = data.drop(\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "819d0cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import round, col\n",
    "\n",
    "data = data.withColumn(\"grade\", regexp_replace(\"grade\", \",\", \".\"))\n",
    "data = data.withColumn(\"grade\", data[\"grade\"].cast(\"double\"))\n",
    "data = data.withColumn(\"youtube\", data[\"youtube\"].cast(\"integer\"))\n",
    "data = data.withColumn(\"spotify\", data[\"spotify\"].cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e37ab23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "data = data.withColumn(\"new_old\", when(data[\"year\"] > 2016, 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "56e06428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- album: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- spotify: integer (nullable = true)\n",
      " |-- youtube: integer (nullable = true)\n",
      " |-- grade: double (nullable = true)\n",
      " |-- new_old: integer (nullable = false)\n",
      "\n",
      "['album', 'title', 'year', 'duration', 'spotify', 'youtube', 'grade', 'new_old']\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "70e99460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"album\", outputCol=\"AlbumIndex\")\n",
    "indexed = indexer.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5db08872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['year', 'duration', 'spotify', 'youtube', 'AlbumIndex'], \n",
    "outputCol=\"features\",\n",
    "handleInvalid=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "016fc0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|            features|new_old|\n",
      "+--------------------+-------+\n",
      "|[2006.0,232.0,102...|      0|\n",
      "|[2008.0,173.0,143...|      0|\n",
      "|[2007.0,203.0,177...|      0|\n",
      "|[2008.0,242.0,92....|      0|\n",
      "|[2007.0,201.0,243...|      0|\n",
      "|[2006.0,213.0,38....|      0|\n",
      "|[2008.0,241.0,167...|      0|\n",
      "|[2008.0,294.0,106...|      0|\n",
      "|[2008.0,235.0,766...|      0|\n",
      "|[2008.0,234.0,104...|      0|\n",
      "|[2008.0,231.0,554...|      0|\n",
      "|[2008.0,261.0,54....|      0|\n",
      "|[2008.0,243.0,309...|      0|\n",
      "|[2008.0,245.0,39....|      0|\n",
      "|[2008.0,279.0,34....|      0|\n",
      "|[2008.0,237.0,31....|      0|\n",
      "|[2008.0,263.0,28....|      0|\n",
      "|[2021.0,277.0,284...|      1|\n",
      "|[2010.0,237.0,38....|      0|\n",
      "|[2010.0,231.0,107...|      0|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = assembler.transform(indexed)\n",
    "output.select(\"features\", \"new_old\").show()\n",
    "final_data = output.select(\"features\", \"new_old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "188147b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           new_old|\n",
      "+-------+------------------+\n",
      "|  count|                85|\n",
      "|   mean|               0.6|\n",
      "| stddev|0.4928053803045811|\n",
      "|    min|                 0|\n",
      "|    max|                 1|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|            new_old|\n",
      "+-------+-------------------+\n",
      "|  count|                 82|\n",
      "|   mean| 0.6707317073170732|\n",
      "| stddev|0.47283954548277546|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.5, 0.5])\n",
    "\n",
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9a0f47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (DecisionTreeClassifier, GBTClassifier, RandomForestClassifier)\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "d269969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(labelCol=\"new_old\", featuresCol=\"features\")\n",
    "rfc = RandomForestClassifier(labelCol=\"new_old\", featuresCol=\"features\")\n",
    "gbt = GBTClassifier(labelCol=\"new_old\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "6da1b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "7a5f7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test_data)\n",
    "rfc_preds = rfc_model.transform(test_data)\n",
    "gbt_preds = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c0a39ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "my_binary_eval = BinaryClassificationEvaluator(labelCol=\"new_old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "815024f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"DTC:\")\n",
    "print(my_binary_eval.evaluate(dtc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "93c189c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"RFC:\")\n",
    "print(my_binary_eval.evaluate(rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1b42597d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"GBT:\")\n",
    "print(my_binary_eval.evaluate(gbt_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a95c16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "acc_eval = MulticlassClassificationEvaluator(labelCol=\"new_old\", metricName=\"accuracy\")\n",
    "rfc_acc = acc_eval.evaluate(rfc_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "31940dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ffec51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
