{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "47bfcf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+----+-------------------+-------+-------+-----+\n",
      "|       album|               title|year|           duration|spotify|youtube|grade|\n",
      "+------------+--------------------+----+-------------------+-------+-------+-----+\n",
      "|Taylor Swift|          Tim McGraw|2006|2024-02-04 03:52:00|    102|     50|  7,9|\n",
      "|Taylor Swift|     Picture To Burn|2008|2024-02-04 02:53:00|    143|    118| 8,85|\n",
      "|Taylor Swift|Teardrops On My G...|2007|2024-02-04 03:23:00|    177|    166|  8,7|\n",
      "|Taylor Swift|A Place in This W...|2006|2024-02-04 03:19:00|     30|    0,7| 9,25|\n",
      "|Taylor Swift|         Cold As You|2006|2024-02-04 03:59:00|     31|   0,75| 7,85|\n",
      "|Taylor Swift|         The Outside|2006|2024-02-04 03:27:00|     21|    0,5| 7,55|\n",
      "|Taylor Swift|Tied Together wit...|2006|2024-02-04 04:08:00|     24|    0,5| 7,35|\n",
      "|Taylor Swift|      Stay Beautiful|2006|2024-02-04 03:56:00|     26|    0,5|  6,5|\n",
      "|Taylor Swift|   Should've Said No|2008|2024-02-04 04:02:00|     92|      2| 8,35|\n",
      "|Taylor Swift|Mary's Song (Oh M...|2006|2024-02-04 03:33:00|     33|    0,6|  7,4|\n",
      "|Taylor Swift|            Our Song|2007|2024-02-04 03:21:00|    243|    207| 8,65|\n",
      "|Taylor Swift|I'm Only Me When ...|2006|2024-02-04 03:33:00|     38|     53|  8,6|\n",
      "|Taylor Swift|           Invisible|2006|2024-02-04 03:23:00|     26|    0,5|    8|\n",
      "|Taylor Swift|A Perfectly Good ...|2007|2024-02-04 03:40:00|     18|    0,4|  6,8|\n",
      "|    Fearless|            Fearless|2008|2024-02-04 04:01:00|    167|     61|9,725|\n",
      "|    Fearless|             Fifteen|2008|2024-02-04 04:54:00|    106|    166|  7,6|\n",
      "|    Fearless|          Love Story|2008|2024-02-04 03:55:00|    766|    696| 9,45|\n",
      "|    Fearless|         Hey Stephen|2008|2024-02-04 04:14:00|     68|    7,5| 7,95|\n",
      "|    Fearless|         White Horse|2008|2024-02-04 03:54:00|    104|    158|  8,2|\n",
      "|    Fearless|  You Belong With Me|2008|2024-02-04 03:51:00|    554|   1492| 9,74|\n",
      "+------------+--------------------+----+-------------------+-------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"taylor\").getOrCreate()\n",
    "df = spark.read.csv(\"taylor.csv\", header=True, inferSchema=True, sep=\";\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "68617285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- album: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- spotify: integer (nullable = true)\n",
      " |-- youtube: integer (nullable = true)\n",
      " |-- grade: double (nullable = true)\n",
      "\n",
      "['album', 'title', 'year', 'duration', 'spotify', 'youtube', 'grade']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import hour, minute, col\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df = df.withColumn(\"grade\", regexp_replace(\"grade\", \",\", \".\"))\n",
    "df = df.withColumn(\"grade\", df[\"grade\"].cast(\"double\"))\n",
    "df = df.withColumn(\"youtube\", df[\"youtube\"].cast(\"integer\"))\n",
    "\n",
    "\n",
    "df = df.withColumn(\"minutes\", hour(\"duration\"))\n",
    "df = df.withColumn(\"seconds\", minute(\"duration\"))\n",
    "df = df.withColumn(\"duration\", col(\"minutes\") * 60 + col(\"seconds\")).drop(\"hour\", \"minute\")\n",
    "df = df.withColumn(\"duration\", df[\"duration\"].cast(\"integer\"))\n",
    "df = df.drop(\"minutes\")\n",
    "df = df.drop(\"seconds\")\n",
    "\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "cols = df.columns\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "50ffaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"album\", outputCol=\"album_index\")\n",
    "indexed = indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "57b883cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    'year',\n",
    "'duration',\n",
    " 'spotify',\n",
    " 'youtube',\n",
    " 'album_index'], \n",
    "outputCol=\"features\",\n",
    "handleInvalid=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "a2392b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|grade|\n",
      "+--------------------+-----+\n",
      "|[2006.0,232.0,102...|  7.9|\n",
      "|[2008.0,173.0,143...| 8.85|\n",
      "|[2007.0,203.0,177...|  8.7|\n",
      "|[2008.0,242.0,92....| 8.35|\n",
      "|[2007.0,201.0,243...| 8.65|\n",
      "|[2006.0,213.0,38....|  8.6|\n",
      "|[2008.0,241.0,167...|9.725|\n",
      "|[2008.0,294.0,106...|  7.6|\n",
      "|[2008.0,235.0,766...| 9.45|\n",
      "|[2008.0,234.0,104...|  8.2|\n",
      "|[2008.0,231.0,554...| 9.74|\n",
      "|[2008.0,261.0,54....|  7.2|\n",
      "|[2008.0,243.0,309...| 9.65|\n",
      "|[2008.0,245.0,39....|  6.9|\n",
      "|[2008.0,279.0,34....| 7.65|\n",
      "|[2008.0,237.0,31....| 7.35|\n",
      "|[2008.0,263.0,28....| 7.45|\n",
      "|[2021.0,277.0,284...|  9.2|\n",
      "|[2010.0,237.0,38....| 8.75|\n",
      "|[2010.0,231.0,107...|  9.2|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = assembler.transform(indexed)\n",
    "output.select(\"features\", \"grade\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "afe83c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = output.select(\"features\", \"grade\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "a6a562af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1412a31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m      2\u001b[0m test_data\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "550639db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "taylor_lr = LinearRegression(labelCol=\"grade\")\n",
    "trained_taylor_model = taylor_lr.fit(train_data)\n",
    "\n",
    "taylor_results = trained_taylor_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "5b271c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3899618056470763"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taylor_results.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "66da0ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5857403741129606"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taylor_results.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3cac7d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5032361843606562"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taylor_results.meanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "982b0491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34309178586599104"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taylor_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "bf75e408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['album', 'title', 'year', 'duration', 'spotify', 'youtube', 'grade']"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "a688e74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|corr(grade, spotify)|\n",
      "+--------------------+\n",
      "|  0.5363427965233678|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "df.select(corr(\"grade\", \"spotify\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b4b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
